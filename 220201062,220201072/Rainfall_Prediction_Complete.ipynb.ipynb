{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d845268d",
   "metadata": {},
   "source": [
    "# Rainfall Prediction Using Machine Learning\n",
    "## A Comparative Study of Regression and Classification Models\n",
    "\n",
    "This project implements and compares multiple machine learning algorithms for rainfall prediction in Rangpur, Bangladesh using authentic meteorological data.\n",
    "\n",
    "**Study Area:** Rangpur, Bangladesh (25.7439¬∞N, 89.2752¬∞E)  \n",
    "**Dataset:** 3-year historical weather data (2022-2024)  \n",
    "**Records:** 1,096 daily observations  \n",
    "**Data Source:** Open-Meteo Weather API  \n",
    "**Models Implemented:** 6 Regression + 6 Classification algorithms  \n",
    "\n",
    "**Objectives:**\n",
    "1. Predict rainfall amount (Regression)\n",
    "2. Predict rain occurrence (Classification)\n",
    "3. Compare model performance\n",
    "4. Visualize results comprehensively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193ea36",
   "metadata": {},
   "source": [
    "## 1. Library Imports\n",
    "Import required Python libraries for data processing, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057bcf8",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "Load the preprocessed dataset from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17405a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"Rangpur, Bangladesh\"\n",
    "LATITUDE = 25.7439\n",
    "LONGITUDE = 89.2752\n",
    "\n",
    "df = pd.read_csv('data/rangpur_daily_weather.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Location: {LOCATION}\")\n",
    "print(f\"Coordinates: {LATITUDE}¬∞N, {LONGITUDE}¬∞E\")\n",
    "print(f\"Data Period: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Total Records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d07ad",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "Examine dataset structure, statistics, and data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd68b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"No missing values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data overview\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('üìä Exploratory Data Analysis - Rangpur Weather Dataset', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "# 1. Temperature distribution\n",
    "axes[0, 0].hist(df['mean_temperature'], bins=30, color='#FF6B6B', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Temperature Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Mean Temperature (¬∞C)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['mean_temperature'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"mean_temperature\"].mean():.1f}¬∞C')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Rainfall distribution\n",
    "axes[0, 1].hist(df[df['rain_sum'] > 0]['rain_sum'], bins=30, color='#4ECDC4', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Rainfall Amount Distribution (Rainy Days Only)', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Rainfall (mm)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df[df['rain_sum'] > 0]['rain_sum'].mean(), color='blue', linestyle='--', linewidth=2, label=f'Mean: {df[df[\"rain_sum\"] > 0][\"rain_sum\"].mean():.1f}mm')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Rainy vs Non-Rainy Days\n",
    "rain_counts = df['will_rain'].value_counts()\n",
    "colors_pie = ['#FFD93D', '#4ECDC4']\n",
    "axes[0, 2].pie(rain_counts, labels=['No Rain', 'Rain'], autopct='%1.1f%%', colors=colors_pie, startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[0, 2].set_title(f'Rainy vs Non-Rainy Days\\n(Total: {len(df)} days)', fontweight='bold')\n",
    "\n",
    "# 4. Monthly rainfall pattern\n",
    "monthly_rain = df.groupby('month')['rain_sum'].sum()\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "axes[1, 0].bar(range(1, 13), monthly_rain, color='#95E1D3', edgecolor='black', alpha=0.8)\n",
    "axes[1, 0].set_title('Monthly Total Rainfall', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Total Rainfall (mm)')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(months, rotation=45)\n",
    "axes[1, 0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 5. Seasonal rainfall\n",
    "season_rain = df.groupby('season')['rain_sum'].sum().sort_values(ascending=False)\n",
    "colors_bar = ['#F38181', '#AA96DA', '#FCBAD3', '#FFFFD2']\n",
    "axes[1, 1].barh(season_rain.index, season_rain.values, color=colors_bar, edgecolor='black', alpha=0.8)\n",
    "axes[1, 1].set_title('Seasonal Total Rainfall', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Total Rainfall (mm)')\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "for i, v in enumerate(season_rain.values):\n",
    "    axes[1, 1].text(v + 50, i, f'{v:.0f}mm', va='center', fontweight='bold')\n",
    "\n",
    "# 6. Temperature vs Rainfall scatter\n",
    "axes[1, 2].scatter(df['mean_temperature'], df['rain_sum'], alpha=0.4, c=df['rain_sum'], cmap='Blues', s=30, edgecolor='black', linewidth=0.5)\n",
    "axes[1, 2].set_title('Temperature vs Rainfall Relationship', fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Mean Temperature (¬∞C)')\n",
    "axes[1, 2].set_ylabel('Rainfall (mm)')\n",
    "axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà EDA Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e522ca",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "Handle missing values and prepare dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f43394",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_before = df.isnull().sum().sum()\n",
    "print(f\"Missing values before: {missing_before}\")\n",
    "print(\"\\nMissing values by column:\")\n",
    "missing_cols = df.isnull().sum()\n",
    "print(missing_cols[missing_cols > 0])\n",
    "\n",
    "# Handle missing values using multiple strategies\n",
    "# 1. Drop rows with missing target variables\n",
    "df = df.dropna(subset=['previous_day_rainfall', 'previous_week_rainfall', 'rain_sum'])\n",
    "\n",
    "# 2. Fill numerical columns with median\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "missing_after = df.isnull().sum().sum()\n",
    "print(f\"\\nMissing values after: {missing_after}\")\n",
    "print(f\"Rows remaining: {len(df)}\")\n",
    "\n",
    "print(f\"\\nRainfall Statistics:\")\n",
    "print(f\"Rainy days: {df['will_rain'].sum()} ({df['will_rain'].sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"Total rainfall: {df['rain_sum'].sum():.2f} mm\")\n",
    "print(f\"Average daily: {df['rain_sum'].mean():.2f} mm\")\n",
    "print(f\"Maximum daily: {df['rain_sum'].max():.2f} mm\")\n",
    "\n",
    "print(f\"\\nRainy days by season:\")\n",
    "print(df.groupby('season')['will_rain'].sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a45be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values and preprocessing results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('üîß Data Preprocessing Visualization', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. Missing values by column (before preprocessing)\n",
    "missing_data = missing_cols[missing_cols > 0].sort_values(ascending=False)\n",
    "axes[0].barh(range(len(missing_data)), missing_data.values, color='#FF6B6B', edgecolor='black', alpha=0.8)\n",
    "axes[0].set_yticks(range(len(missing_data)))\n",
    "axes[0].set_yticklabels(missing_data.index)\n",
    "axes[0].set_xlabel('Number of Missing Values')\n",
    "axes[0].set_title(f'Missing Values by Column\\n(Total: {missing_before})', fontweight='bold')\n",
    "axes[0].grid(alpha=0.3, axis='x')\n",
    "for i, v in enumerate(missing_data.values):\n",
    "    axes[0].text(v + 1, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "# 2. Rainfall statistics\n",
    "categories = ['Total\\nDays', 'Rainy\\nDays', 'Non-Rainy\\nDays']\n",
    "values = [len(df), df['will_rain'].sum(), len(df) - df['will_rain'].sum()]\n",
    "colors = ['#95E1D3', '#4ECDC4', '#FFD93D']\n",
    "bars = axes[1].bar(categories, values, color=colors, edgecolor='black', alpha=0.8, width=0.6)\n",
    "axes[1].set_ylabel('Number of Days')\n",
    "axes[1].set_title('Dataset Composition After Preprocessing', fontweight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "for bar, val in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 15, f'{val}\\n({val/len(df)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîß Preprocessing Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3453d9d",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "Create derived features to enhance model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_range'] = df['max_temperature'] - df['min_temperature']\n",
    "df['wind_variability'] = df['max_wind_gust'] - df['max_wind_speed']\n",
    "df['is_monsoon'] = (df['season'] == 'Monsoon').astype(int)\n",
    "df['is_summer'] = (df['season'] == 'Spring').astype(int)\n",
    "df['is_winter'] = (df['season'] == 'Winter').astype(int)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['sunshine_hours'] = df['sunshine_duration'] / 3600\n",
    "\n",
    "np.random.seed(42)\n",
    "for col in ['max_temperature', 'min_temperature', 'mean_temperature', \n",
    "            'max_wind_speed', 'evapotranspiration']:\n",
    "    noise = np.random.normal(0, df[col].std() * 0.005, len(df))\n",
    "    df[col] = df[col] + noise\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(f\"Total features: {df.shape[1]}\")\n",
    "print(f\"Total rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('üî¨ Feature Engineering - Derived Features Distribution', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "features_to_plot = ['temp_range', 'wind_variability', 'sunshine_hours', 'month_sin', 'month_cos', 'is_monsoon']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#95E1D3', '#FFD93D', '#AA96DA', '#F38181']\n",
    "\n",
    "for idx, (ax, feature, color) in enumerate(zip(axes.flat, features_to_plot, colors)):\n",
    "    ax.hist(df[feature], bins=30, color=color, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{feature.replace(\"_\", \" \").title()}', fontweight='bold')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.axvline(df[feature].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[feature].mean():.2f}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî¨ Feature Engineering Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df31b0",
   "metadata": {},
   "source": [
    "## 6. Data Splitting and Normalization\n",
    "Split dataset into training and testing sets, then apply feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['date', 'season', 'sunshine_duration', 'weathercode', 'location', \n",
    "             'previous_day_rainfall']\n",
    "X = df.drop(columns=drop_cols + ['rain_sum', 'will_rain', 'precipitation_sum'], errors='ignore')\n",
    "y_regression = df['rain_sum']\n",
    "y_classification = df['will_rain']\n",
    "\n",
    "print(f\"Feature count: {X.shape[1]}\")\n",
    "print(f\"Sample size: {X.shape[0]}\")\n",
    "\n",
    "X_train, X_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42)\n",
    "_, _, y_clf_train, y_clf_test = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set: {len(X_train)} samples\")\n",
    "print(f\"Testing set: {len(X_test)} samples\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Data preparation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dab4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train-test split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('üìä Train-Test Split Visualization', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 1. Split ratio\n",
    "split_data = [len(X_train), len(X_test)]\n",
    "labels = [f'Training Set\\n({len(X_train)} samples)', f'Test Set\\n({len(X_test)} samples)']\n",
    "colors = ['#4ECDC4', '#FF6B6B']\n",
    "explode = (0.05, 0.05)\n",
    "axes[0].pie(split_data, labels=labels, autopct='%1.1f%%', colors=colors, explode=explode, \n",
    "           startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "axes[0].set_title(f'Data Split Ratio\\n(Total: {len(X_train) + len(X_test)} samples)', fontweight='bold')\n",
    "\n",
    "# 2. Target distribution in train vs test\n",
    "train_rain = y_clf_train.sum()\n",
    "train_no_rain = len(y_clf_train) - train_rain\n",
    "test_rain = y_clf_test.sum()\n",
    "test_no_rain = len(y_clf_test) - test_rain\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "bars1 = axes[1].bar(x - width/2, [train_rain, test_rain], width, label='Rain', color='#4ECDC4', edgecolor='black', alpha=0.8)\n",
    "bars2 = axes[1].bar(x + width/2, [train_no_rain, test_no_rain], width, label='No Rain', color='#FFD93D', edgecolor='black', alpha=0.8)\n",
    "\n",
    "axes[1].set_ylabel('Number of Samples')\n",
    "axes[1].set_title('Target Distribution: Train vs Test', fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(['Training Set', 'Test Set'])\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2., height + 5, f'{int(height)}', \n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä Train-Test Split Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fb4bd",
   "metadata": {},
   "source": [
    "## 7. Regression Model Training\n",
    "Train multiple regression models to predict continuous rainfall values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = []\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=10.0),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=8, min_samples_split=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=5, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, learning_rate=0.05, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.05, random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "print(\"Training Regression Models...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_reg_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_reg_test, y_pred))\n",
    "    mae = mean_absolute_error(y_reg_test, y_pred)\n",
    "    r2 = r2_score(y_reg_test, y_pred)\n",
    "    \n",
    "    regression_results.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2_Score': r2\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:20} | R¬≤: {r2:.3f} | RMSE: {rmse:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(models)} regression models trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('üìà Regression Models Performance', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "model_names = [result['Model'] for result in regression_results]\n",
    "colors_grad = plt.cm.viridis(np.linspace(0.3, 0.9, len(model_names)))\n",
    "\n",
    "# 1. R¬≤ Score comparison\n",
    "r2_scores = [result['R2_Score'] for result in regression_results]\n",
    "bars = axes[0].barh(model_names, r2_scores, color=colors_grad, edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xlabel('R¬≤ Score')\n",
    "axes[0].set_title('R¬≤ Score by Model', fontweight='bold')\n",
    "axes[0].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, r2_scores)):\n",
    "    axes[0].text(score + 0.01, i, f'{score:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# 2. RMSE comparison\n",
    "rmse_scores = [result['RMSE'] for result in regression_results]\n",
    "bars = axes[1].barh(model_names, rmse_scores, color=colors_grad, edgecolor='black', alpha=0.8)\n",
    "axes[1].set_xlabel('RMSE (mm)')\n",
    "axes[1].set_title('RMSE by Model (Lower is Better)', fontweight='bold')\n",
    "axes[1].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, rmse_scores)):\n",
    "    axes[1].text(score + 0.2, i, f'{score:.2f}', va='center', fontweight='bold')\n",
    "\n",
    "# 3. MAE comparison\n",
    "mae_scores = [result['MAE'] for result in regression_results]\n",
    "bars = axes[2].barh(model_names, mae_scores, color=colors_grad, edgecolor='black', alpha=0.8)\n",
    "axes[2].set_xlabel('MAE (mm)')\n",
    "axes[2].set_title('MAE by Model (Lower is Better)', fontweight='bold')\n",
    "axes[2].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, mae_scores)):\n",
    "    axes[2].text(score + 0.1, i, f'{score:.2f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà Regression Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda28650",
   "metadata": {},
   "source": [
    "## 8. Classification Model Training\n",
    "Train multiple classification models to predict rain occurrence (binary outcome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results = []\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, C=0.5, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=6, min_samples_split=15, min_samples_leaf=8, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=80, max_depth=8, min_samples_split=12, min_samples_leaf=6, max_features='sqrt', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=60, max_depth=4, learning_rate=0.08, subsample=0.8, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=60, max_depth=5, learning_rate=0.08, subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, random_state=42, verbosity=0),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"Training Classification Models...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_clf_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_clf_test, y_pred)\n",
    "    precision = precision_score(y_clf_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_clf_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_clf_test, y_pred, zero_division=0)\n",
    "    \n",
    "    classification_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:20} | Accuracy: {acc:.3f} | F1: {f1:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(models)} classification models trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classification results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('üéØ Classification Models Performance', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "clf_model_names = [result['Model'] for result in classification_results]\n",
    "colors_clf = plt.cm.plasma(np.linspace(0.2, 0.9, len(clf_model_names)))\n",
    "\n",
    "# 1. Accuracy comparison\n",
    "acc_scores = [result['Accuracy'] for result in classification_results]\n",
    "bars = axes[0, 0].barh(clf_model_names, acc_scores, color=colors_clf, edgecolor='black', alpha=0.8)\n",
    "axes[0, 0].set_xlabel('Accuracy (%)')\n",
    "axes[0, 0].set_title('Test Accuracy by Model', fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, acc_scores)):\n",
    "    axes[0, 0].text(score + 0.5, i, f'{score:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "# 2. F1-Score comparison\n",
    "f1_scores = [result['F1_Score'] for result in classification_results]\n",
    "bars = axes[0, 1].barh(clf_model_names, f1_scores, color=colors_clf, edgecolor='black', alpha=0.8)\n",
    "axes[0, 1].set_xlabel('F1-Score (%)')\n",
    "axes[0, 1].set_title('F1-Score by Model', fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, f1_scores)):\n",
    "    axes[0, 1].text(score + 0.5, i, f'{score:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "# 3. Precision comparison\n",
    "prec_scores = [result['Precision'] for result in classification_results]\n",
    "bars = axes[1, 0].barh(clf_model_names, prec_scores, color=colors_clf, edgecolor='black', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Precision (%)')\n",
    "axes[1, 0].set_title('Precision by Model', fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, prec_scores)):\n",
    "    axes[1, 0].text(score + 0.5, i, f'{score:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "# 4. Recall comparison\n",
    "rec_scores = [result['Recall'] for result in classification_results]\n",
    "bars = axes[1, 1].barh(clf_model_names, rec_scores, color=colors_clf, edgecolor='black', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Recall (%)')\n",
    "axes[1, 1].set_title('Recall by Model', fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3, axis='x')\n",
    "for i, (bar, score) in enumerate(zip(bars, rec_scores)):\n",
    "    axes[1, 1].text(score + 0.5, i, f'{score:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ Classification Visualization Complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc2ae9",
   "metadata": {},
   "source": [
    "## 9. Regression Results Analysis\n",
    "Tabular comparison of regression model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.DataFrame(regression_results).sort_values('R2_Score', ascending=False)\n",
    "display(df_reg)\n",
    "\n",
    "best = df_reg.iloc[0]\n",
    "print(f\"\\nüèÜ Best Model: {best['Model']}\")\n",
    "print(f\"R¬≤ Score: {best['R2_Score']:.4f}\")\n",
    "print(f\"RMSE: {best['RMSE']:.4f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a2afe",
   "metadata": {},
   "source": [
    "## 10. Classification Results Analysis\n",
    "Tabular comparison of classification model performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = pd.DataFrame(classification_results).sort_values('Accuracy', ascending=False)\n",
    "display(df_clf)\n",
    "\n",
    "best = df_clf.iloc[0]\n",
    "print(f\"\\nüèÜ Best Model: {best['Model']}\")\n",
    "print(f\"Accuracy: {best['Accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {best['F1_Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b15d44",
   "metadata": {},
   "source": [
    "## Step 11: Model Performance Visualization\n",
    "Comprehensive visual comparison of all regression and classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a08660",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Regression Models - R¬≤ Score\n",
    "ax1 = plt.subplot(3, 2, 1)\n",
    "bars1 = ax1.barh(df_reg['Model'], df_reg['R2_Score'], color='steelblue', edgecolor='navy', alpha=0.7)\n",
    "ax1.set_xlabel('R¬≤ Score', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Regression: R¬≤ Score Comparison', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax1.set_xlim(0, 1)\n",
    "for i, bar in enumerate(bars1):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.02, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "             ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Regression Models - RMSE\n",
    "ax2 = plt.subplot(3, 2, 2)\n",
    "bars2 = ax2.barh(df_reg['Model'], df_reg['RMSE'], color='coral', edgecolor='darkred', alpha=0.7)\n",
    "ax2.set_xlabel('RMSE (mm)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Regression: RMSE Comparison (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "for i, bar in enumerate(bars2):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width + 0.3, bar.get_y() + bar.get_height()/2, f'{width:.2f}', \n",
    "             ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Regression Models - MAE\n",
    "ax3 = plt.subplot(3, 2, 3)\n",
    "bars3 = ax3.barh(df_reg['Model'], df_reg['MAE'], color='lightgreen', edgecolor='darkgreen', alpha=0.7)\n",
    "ax3.set_xlabel('MAE (mm)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Regression: Mean Absolute Error', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "for i, bar in enumerate(bars3):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width + 0.2, bar.get_y() + bar.get_height()/2, f'{width:.2f}', \n",
    "             ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Classification Models - Accuracy\n",
    "ax4 = plt.subplot(3, 2, 4)\n",
    "bars4 = ax4.barh(df_clf['Model'], df_clf['Accuracy'], color='mediumpurple', edgecolor='indigo', alpha=0.7)\n",
    "ax4.set_xlabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Classification: Accuracy Comparison', fontsize=12, fontweight='bold')\n",
    "ax4.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax4.set_xlim(0.85, 1.01)\n",
    "for i, bar in enumerate(bars4):\n",
    "    width = bar.get_width()\n",
    "    ax4.text(width + 0.003, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "             ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Classification Models - F1 Score\n",
    "ax5 = plt.subplot(3, 2, 5)\n",
    "bars5 = ax5.barh(df_clf['Model'], df_clf['F1_Score'], color='gold', edgecolor='orange', alpha=0.7)\n",
    "ax5.set_xlabel('F1-Score', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('Classification: F1-Score Comparison', fontsize=12, fontweight='bold')\n",
    "ax5.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "ax5.set_xlim(0.85, 1.01)\n",
    "for i, bar in enumerate(bars5):\n",
    "    width = bar.get_width()\n",
    "    ax5.text(width + 0.003, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "             ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Classification Models - Precision vs Recall\n",
    "ax6 = plt.subplot(3, 2, 6)\n",
    "x_pos = np.arange(len(df_clf['Model']))\n",
    "width = 0.35\n",
    "bars6a = ax6.bar(x_pos - width/2, df_clf['Precision'], width, label='Precision', \n",
    "                  color='skyblue', edgecolor='blue', alpha=0.7)\n",
    "bars6b = ax6.bar(x_pos + width/2, df_clf['Recall'], width, label='Recall', \n",
    "                  color='salmon', edgecolor='red', alpha=0.7)\n",
    "ax6.set_xlabel('Models', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('Classification: Precision vs Recall', fontsize=12, fontweight='bold')\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels(df_clf['Model'], rotation=45, ha='right', fontsize=9)\n",
    "ax6.legend(loc='lower right', fontsize=10)\n",
    "ax6.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax6.set_ylim(0.85, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä All model performance metrics visualized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c96e44",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix Analysis\n",
    "Detailed evaluation of the best classification model using confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf_model = RandomForestClassifier(n_estimators=80, max_depth=8, min_samples_split=12, min_samples_leaf=6, max_features='sqrt', random_state=42)\n",
    "best_clf_model.fit(X_train_scaled, y_clf_train)\n",
    "y_pred = best_clf_model.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_clf_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_clf_test, y_pred, target_names=['No Rain', 'Rain']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe658289",
   "metadata": {},
   "source": [
    "## 13. Conclusion and Summary\n",
    "Final overview of the project results and best performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PROJECT SUMMARY: RAINFALL PREDICTION USING MACHINE LEARNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìç Study Area: {LOCATION}\")\n",
    "print(f\"üìÖ Data Period: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"üìä Total Records: {len(df)} daily observations\")\n",
    "print(f\"üî¢ Features Used: {X.shape[1]}\")\n",
    "print(f\"üåßÔ∏è Rainy Days: {df['will_rain'].sum()} ({df['will_rain'].sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'REGRESSION TASK (Rainfall Amount Prediction)':^70}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"üèÜ Best Model: {df_reg.iloc[0]['Model']}\")\n",
    "print(f\"   R¬≤ Score: {df_reg.iloc[0]['R2_Score']:.4f}\")\n",
    "print(f\"   RMSE: {df_reg.iloc[0]['RMSE']:.2f} mm\")\n",
    "print(f\"   MAE: {df_reg.iloc[0]['MAE']:.2f} mm\")\n",
    "\n",
    "print(f\"\\n{'CLASSIFICATION TASK (Rain Occurrence Prediction)':^70}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"üèÜ Best Model: {df_clf.iloc[0]['Model']}\")\n",
    "print(f\"   Accuracy: {df_clf.iloc[0]['Accuracy']:.4f} ({df_clf.iloc[0]['Accuracy']*100:.2f}%)\")\n",
    "print(f\"   Precision: {df_clf.iloc[0]['Precision']:.4f}\")\n",
    "print(f\"   Recall: {df_clf.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"   F1-Score: {df_clf.iloc[0]['F1_Score']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Project completed successfully\")\n",
    "print(\"‚úÖ All models evaluated on real-world weather data\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8fd09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
